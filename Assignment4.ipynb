{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to **Preview the Grading** for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "This assignment requires that you to find **at least** two datasets on the web which are related, and that you visualize these datasets to answer a question with the broad topic of **economic activity or measures** (see below) for the region of **Ann Arbor, Michigan, United States**, or **United States** more broadly.\n",
    "\n",
    "You can merge these datasets with data from different regions if you like! For instance, you might want to compare **Ann Arbor, Michigan, United States** to Ann Arbor, USA. In that case at least one source file must be about **Ann Arbor, Michigan, United States**.\n",
    "\n",
    "You are welcome to choose datasets at your discretion, but keep in mind **they will be shared with your peers**, so choose appropriate datasets. Sensitive, confidential, illicit, and proprietary materials are not good choices for datasets for this assignment. You are welcome to upload datasets of your own as well, and link to them using a third party repository such as github, bitbucket, pastebin, etc. Please be aware of the Coursera terms of service with respect to intellectual property.\n",
    "\n",
    "Also, you are welcome to preserve data in its original language, but for the purposes of grading you should provide english translations. You are welcome to provide multiple visuals in different languages if you would like!\n",
    "\n",
    "As this assignment is for the whole course, you must incorporate principles discussed in the first week, such as having as high data-ink ratio (Tufte) and aligning with Cairoâ€™s principles of truth, beauty, function, and insight.\n",
    "\n",
    "Here are the assignment instructions:\n",
    "\n",
    " * State the region and the domain category that your data sets are about (e.g., **Ann Arbor, Michigan, United States** and **economic activity or measures**).\n",
    " * You must state a question about the domain category and region that you identified as being interesting.\n",
    " * You must provide at least two links to available datasets. These could be links to files such as CSV or Excel files, or links to websites which might have data in tabular form, such as Wikipedia pages.\n",
    " * You must upload an image which addresses the research question you stated. In addition to addressing the question, this visual should follow Cairo's principles of truthfulness, functionality, beauty, and insightfulness.\n",
    " * You must contribute a short (1-2 paragraph) written justification of how your visualization addresses your stated research question.\n",
    "\n",
    "What do we mean by **economic activity or measures**?  For this category you might look at the inputs or outputs to the given economy, or major changes in the economy compared to other regions.\n",
    "\n",
    "## Tips\n",
    "* Wikipedia is an excellent source of data, and I strongly encourage you to explore it for new data sources.\n",
    "* Many governments run open data initiatives at the city, region, and country levels, and these are wonderful resources for localized data sources.\n",
    "* Several international agencies, such as the [United Nations](http://data.un.org/), the [World Bank](http://data.worldbank.org/), the [Global Open Data Index](http://index.okfn.org/place/) are other great places to look for data.\n",
    "* This assignment requires you to convert and clean datafiles. Check out the discussion forums for tips on how to do this from various sources, and share your successes with your fellow students!\n",
    "\n",
    "## Example\n",
    "Looking for an example? Here's what our course assistant put together for the **Ann Arbor, MI, USA** area using **sports and athletics** as the topic. [Example Solution File](./readonly/Assignment4_example.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Becoming an independent Data Scientist\n",
    "\n",
    "### State the region and the domain category that your data sets are about\n",
    "Region: Ann Arbor, MI, USA\n",
    "\n",
    "Topic: economic activity or measures\n",
    "\n",
    "### Research question about the domain category and region\n",
    "How have the unemployment rate, labor force participation rate and Personal Income per Capita changed over the last two decades in Ann Arbor county (Washtenaw County) compared to the whole Michigan state and country?\n",
    "\n",
    "###  Used publicly accessible datasets\n",
    "The website from the Economic Research of the Federal bank of St Louis was used, which at the same time retrieves the data from the  U.S. Bureau of Labor Statistics (so it is a trusty reesource) but in a more orderly manner. The data was downloaded as csv files.\n",
    "\n",
    "* For the unemployment rate\n",
    "    * USA unemployment rate: https://fred.stlouisfed.org/series/UNRATE#0\n",
    "    * MI unemployment rate: https://fred.stlouisfed.org/series/MIUR#0\n",
    "    * Washtenaw County unemployment rate: https://fred.stlouisfed.org/series/MIWASH1URN#0\n",
    "\n",
    "* For the labor force participation rate\n",
    "    * USA labor force participation rate: https://fred.stlouisfed.org/series/CIVPART#0\n",
    "    * MI labor force participation rate: https://fred.stlouisfed.org/series/LBSSA26\n",
    "    * Washtenaw County labor force participation rate. Here the data was not explicitely available so I will use the absolute labor force and the total resident population in the county and make a simple calculation of the labor force participation rate by dividing the firt by the second.\n",
    "        * Washtenaw County absolute labor force: https://fred.stlouisfed.org/series/MIWASH1LFN\n",
    "        * Washtenaw County resident population: https://fred.stlouisfed.org/series/MIWASH1POP\n",
    "\n",
    "* For the Personal Income per Capita\n",
    "    * USA Personal Income per Capita: https://fred.stlouisfed.org/series/A792RC0A052NBEA\n",
    "    * MI Personal Income per Capita: https://fred.stlouisfed.org/series/MIPCPI\n",
    "    * Washtenaw County Personal Income per Capita: https://fred.stlouisfed.org/series/PCPI26161\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "### Let's start importing the libraries we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import the necessary modules\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "import matplotlib.colors as col\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.widgets import Slider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will import the csv files as dataframes and clean them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import the data from the csv files:\n",
    "df_usa_unem = pd.read_csv('Unemployment+Rate+USA.csv')\n",
    "df_usa_labfo = pd.read_csv('Labor+Force+Participation+Rate+USA.csv')\n",
    "df_usa_pic = pd.read_csv('Personal+income+per+capita+USA.csv')\n",
    "\n",
    "df_mi_unem = pd.read_csv('Unemployment+Rate+MI.csv')\n",
    "df_mi_labfo = pd.read_csv('Labor+Force+Participation+Rate+MI.csv')\n",
    "df_mi_pic = pd.read_csv('Personal+income+per+capita+MI.csv')\n",
    "\n",
    "df_wash_unem = pd.read_csv('Unemployment+Rate+Washtenaw+County.csv')\n",
    "df_wash_abslabfo = pd.read_csv('Civilian+Labor+Force+Washtenaw+County.csv')\n",
    "df_wash_pop = pd.read_csv('Resident+Population+Washtenaw+County.csv')\n",
    "df_wash_pic = pd.read_csv('Personal+income+per+capita+Washtenaw+County.csv')\n",
    "\n",
    "# Lets merge now the dataframes now at every level (country, state and county) nad clean them a little bit\n",
    "df_usa = pd.merge(pd.merge(df_usa_unem, df_usa_labfo, on='DATE', how='inner'),df_usa_pic,on='DATE', how='inner')\n",
    "df_usa.iloc[:,0] = df_usa.iloc[:,0].str.slice(start=0, stop=4).astype(np.float64)\n",
    "df_usa.iloc[:,1] = df_usa.iloc[:,1].round(2)\n",
    "df_usa.iloc[:,2] = df_usa.iloc[:,2].round(2)\n",
    "df_usa.columns = ['Year','Unemployment Rate', 'Labor Force Participation Rate', 'PIC']\n",
    "\n",
    "df_mi = pd.merge(pd.merge(df_mi_unem, df_mi_labfo, on='DATE', how='inner'),df_mi_pic,on='DATE', how='inner')\n",
    "df_mi.iloc[:,0] = df_mi.iloc[:,0].str.slice(start=0, stop=4).astype(np.float64)\n",
    "df_mi.iloc[:,1] = df_mi.iloc[:,1].round(2)\n",
    "df_mi.iloc[:,2] = df_mi.iloc[:,2].round(2)\n",
    "df_mi.columns = ['Year','Unemployment Rate', 'Labor Force Participation Rate', 'PIC']\n",
    "\n",
    "# For Washtenaw county, firstly we need to obtain the Labor Force Participation Rate datframe using the absolute lab force \n",
    "# and the population dataframes\n",
    "df_wash_labfo = pd.merge(df_wash_abslabfo, df_wash_pop, on='DATE', how='inner')\n",
    "# The format of the population column is wrong (point for thousands and python interprets this as decimal) so we need \n",
    "# to multiply by 1000 to obtain the real figures\n",
    "df_wash_labfo.iloc[:,2] = df_wash_labfo.iloc[:,2]*1000\n",
    "# Now we can divide both columns and multiply by 100 to get the rate\n",
    "df_wash_labfo['Labor Force Participation Rate'] = (df_wash_labfo.iloc[:,1]/df_wash_labfo.iloc[:,2])*100\n",
    "# We get rid of the columns we dont need anymore\n",
    "df_wash_labfo = df_wash_labfo.drop(df_wash_labfo.columns[[1, 2]], axis=1) \n",
    "\n",
    "# Now we are ready to merge the dataframes for Washtenaw county\n",
    "df_wash = pd.merge(pd.merge(df_wash_unem, df_wash_labfo, on='DATE', how='inner'),df_wash_pic,on='DATE', how='inner')\n",
    "df_wash.iloc[:,0] = df_wash.iloc[:,0].str.slice(start=0, stop=4).astype(np.float64)\n",
    "df_wash.iloc[:,1] = df_wash.iloc[:,1].round(2)\n",
    "df_wash.iloc[:,2] = df_wash.iloc[:,2].round(2)\n",
    "df_wash.iloc[:,3] = df_wash.iloc[:,3].astype(np.float64)\n",
    "# The columns are renames in a more convenient manner\n",
    "df_wash.columns = ['Year','Unemployment Rate', 'Labor Force Participation Rate', 'PIC']\n",
    "\n",
    "\n",
    "df_usa, df_mi, df_wash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Time to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set first the colormap\n",
    "cmap = cm.get_cmap('bwr_r')\n",
    "\n",
    "# With an input we set the year we want to check and we plot it\n",
    "## given_year = int(input('Which year do you want to check? '))\n",
    "\n",
    "# We will do a multivariable scatter plot, x axis is the unemployment rate, y axis is the Labor Force Participation Rate \n",
    "# and the size and color of the points will vary depending on the PIC\n",
    "\n",
    "\n",
    "data1 = df_usa[df_usa.Year == 2000].reset_index()\n",
    "color1 = data1['Labor Force Participation Rate']\n",
    "    \n",
    "data2 = df_mi[df_mi.Year == 2000].reset_index()   \n",
    "color2 = data2['Labor Force Participation Rate']\n",
    "    \n",
    "data3 = df_wash[df_wash.Year == 2000].reset_index()\n",
    "color3 = data3['Labor Force Participation Rate']\n",
    "        \n",
    "cpick = cm.ScalarMappable(cmap=cmap, norm=col.Normalize(vmin=min(min(df_usa['Labor Force Participation Rate']), min(df_mi['Labor Force Participation Rate']), min(df_wash['Labor Force Participation Rate'])), \n",
    "                                                        vmax=max(max(df_usa['Labor Force Participation Rate']), max(df_mi['Labor Force Participation Rate']), max(df_wash['Labor Force Participation Rate']))))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.subplots_adjust(left = 0.1, bottom = 0.35)\n",
    "\n",
    "\n",
    "p1 = plt.scatter(data1['Unemployment Rate'], data1['PIC'],\n",
    "                s=400, linewidths=1, edgecolors='black', picker = 5)\n",
    "    \n",
    "    \n",
    "p2 = plt.scatter(data2['Unemployment Rate'], data2['PIC'], \n",
    "                s= 400, linewidths = 1, edgecolors = 'black', picker = 5)\n",
    "    \n",
    "p3 = plt.scatter(data3['Unemployment Rate'], data3['PIC'], \n",
    "                s=400, linewidths = 1, edgecolors = 'black', picker = 5)\n",
    "    \n",
    "plt.gca().set_xlim([0, 15])\n",
    "plt.gca().set_ylim([25000,65000])\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_linewidth(0.1)\n",
    "plt.gca().spines['bottom'].set_linewidth(0.1)\n",
    "#plt.colorbar(cpick, orientation=\"vertical\").set_label('Personal Income per Capita', fontsize=8)\n",
    "plt.legend([\"USA\", \"Michigan\", \"Washtenaw County\"],loc =\"upper right\", markerscale=0.3, fontsize=6, frameon=False)\n",
    "plt.gca().set_xlabel(\"Unemployment rate\", fontsize=10)\n",
    "plt.gca().set_ylabel(\"Personal Income per Capita\",fontsize=10)\n",
    "plt.gca().set_title('Unemployment rate and Personal Income per Capita \\nbetween 2000 and 2018',fontsize = 12, fontweight = 'bold')\n",
    "plt.gca().title.set_position([.5, 1.03])\n",
    "plt. xticks(fontsize=8)\n",
    "plt. yticks(fontsize=8)\n",
    "\n",
    "Slider_year = plt.axes([0.1,0.2,0.8,0.05])\n",
    "sldr = Slider(Slider_year, 'Year', valmin = 2000, valmax = 2018, \n",
    "              valinit=2000,valfmt='%1.0f', valstep = 1)\n",
    "\n",
    "\n",
    "def val_update(val):\n",
    "    x1 = df_usa[df_usa.Year == sldr.val].reset_index()['Unemployment Rate']\n",
    "    y1 = df_usa[df_usa.Year == sldr.val].reset_index()['PIC']\n",
    "        \n",
    "    x2 = df_mi[df_mi.Year == sldr.val].reset_index()['Unemployment Rate']\n",
    "    y2 = df_mi[df_mi.Year == sldr.val].reset_index()['PIC']\n",
    "        \n",
    "    x3 = df_wash[df_wash.Year == sldr.val].reset_index()['Unemployment Rate']\n",
    "    y3 = df_wash[df_wash.Year == sldr.val].reset_index()['PIC']\n",
    "    \n",
    "    xy1 = np.vstack ((x1, y1))\n",
    "    p1.set_offsets (xy1.T)\n",
    "    #p1.set_array(cpick.to_rgba(df_usa[df_usa.Year == sldr.val].reset_index().PIC))\n",
    "    \n",
    "    xy2 = np.vstack ((x2, y2))\n",
    "    p2.set_offsets (xy2.T)\n",
    "    #p2.set_array(cpick.to_rgba(df_mi[df_mi.Year == sldr.val].reset_index().PIC))\n",
    "    \n",
    "    xy3 = np.vstack ((x3, y3))\n",
    "    p3.set_offsets (xy3.T)\n",
    "    #p3.set_array(cpick.to_rgba(df_wash[df_wash.Year == sldr.val].reset_index().PIC))  \n",
    "    \n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "sldr.on_changed(val_update)\n",
    "# Finally the connection between event and function needs to be made:\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
